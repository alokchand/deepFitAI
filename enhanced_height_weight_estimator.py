def _initialize_models(self):
    try:
        self.mp_holistic.close()  # Close previous instance if exists
    except:
        pass        def __init__(self, use_gpu: bool = True, calibration_file: str = "camera_calibration.yaml"):
            self.lock = threading.Lock()  # Add thread lock            def start_enhanced_real_time_processing(self, video_source=0):
                cap = None
                try:
                    cap = cv2.VideoCapture(video_source)
                    # ... rest of the code ...
                finally:
                    if cap is not None:
                        cap.release()                        def _create_basic_weight_models(self):
                            try:
                                os.makedirs('models', exist_ok=True)
                            except Exception as e:
                                print(f"Error creating models directory: {e}")
                                return                                def draw_positioning_guides(self, frame: np.ndarray, detection_status: str, 
                                                          body_parts_status: Dict[str, bool] = None) -> np.ndarray:
                                    if frame is None:
                                        return np.zeros((self.frame_height, self.frame_width, 3), dtype=np.uint8)
                                    overlay = frame.copy()                                    def __init__(self, frame_width: int = 1280, frame_height: int = 720):
                                        # Cache frequently used calculations
                                        self._center_x = frame_width // 2
                                        self._center_y = frame_height // 2                                        def __init__(self, use_gpu: bool = True, calibration_file: str = "camera_calibration.yaml"):
                                            self.lock = threading.Lock()  # Add thread lock for thread safety
                                            self.cleanup_required = False
                                            
                                        def cleanup(self):
                                            """Cleanup resources properly"""
                                            if self.cleanup_required:
                                                try:
                                                    if hasattr(self, 'mp_holistic'):
                                                        self.mp_holistic.close()
                                                    if hasattr(self, 'mp_face_detection'):
                                                        self.mp_face_detection.close()
                                                    if hasattr(self, 'midas_model'):
                                                        self.midas_model = None
                                                    torch.cuda.empty_cache()  # Clear CUDA cache if using GPU
                                                except:
                                                    pass
                                                self.cleanup_required = False                                                def start_integrated_real_time_processing(self, video_source=0):
                                                    cap = None
                                                    try:
                                                        cap = cv2.VideoCapture(video_source)
                                                        if not cap.isOpened():
                                                            raise RuntimeError("Failed to open camera")
                                                        # ... rest of code ...
                                                    finally:
                                                        if cap is not None:
                                                            cap.release()
                                                        cv2.destroyAllWindows()
                                                        self.cleanup()  # Call cleanup method                                                        def get_db_connection():
                                                            try:
                                                                client = MongoClient('mongodb+srv://alokchandm19_db_user:eYfJjjAy0i4mNqQg@cluster0.81dgp52.mongodb.net/', 
                                                                                   serverSelectionTimeoutMS=5000,  # 5 second timeout
                                                                                   connectTimeoutMS=5000)
                                                                client.server_info()  # Test connection
                                                                return client
                                                            except Exception as e:
                                                                print(f"MongoDB connection error: {e}")
                                                                return None
                                                        
                                                        # Use connection pool
                                                        from functools import wraps
                                                        def with_db_connection(f):
                                                            @wraps(f)
                                                            def wrapper(*args, **kwargs):
                                                                client = get_db_connection()
                                                                if client is None:
                                                                    return jsonify({'error': 'Database connection failed'}), 500
                                                                try:
                                                                    return f(client, *args, **kwargs)
                                                                finally:
                                                                    client.close()
                                                            return wrapper                                                            def get_db_connection():
                                                                try:
                                                                    client = MongoClient('mongodb+srv://alokchandm19_db_user:eYfJjjAy0i4mNqQg@cluster0.81dgp52.mongodb.net/', 
                                                                                       serverSelectionTimeoutMS=5000,  # 5 second timeout
                                                                                       connectTimeoutMS=5000)
                                                                    client.server_info()  # Test connection
                                                                    return client
                                                                except Exception as e:
                                                                    print(f"MongoDB connection error: {e}")
                                                                    return None
                                                            
                                                            # Use connection pool
                                                            from functools import wraps
                                                            def with_db_connection(f):
                                                                @wraps(f)
                                                                def wrapper(*args, **kwargs):
                                                                    client = get_db_connection()
                                                                    if client is None:
                                                                        return jsonify({'error': 'Database connection failed'}), 500
                                                                    try:
                                                                        return f(client, *args, **kwargs)
                                                                    finally:
                                                                        client.close()
                                                                return wrapperimport cv2
import numpy as np
import torch
import torchvision.transforms as transforms
from typing import Tuple, Dict, List, Optional, Union
import mediapipe as mp
from dataclasses import dataclass
import time
import threading
from queue import Queue
import os
import json
import glob
from datetime import datetime
import warnings
import math
from enum import Enum
import pickle
import yaml
from scipy.optimize import minimize
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import joblib

# Set seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)
warnings.filterwarnings('ignore', category=FutureWarning)

class DetectionStatus(Enum):
    HUMAN_DETECTED = "human_detected"
    NO_HUMAN = "no_human"
    PARTIAL_BODY = "partial_body"
    GOOD_POSITION = "good_position"
    MEASURING_STABLE = "measuring_stable"
    AUTO_SAVED = "auto_saved"
    CALIBRATION_NEEDED = "calibration_needed"

@dataclass
class MeasurementResult:
    height_cm: float
    weight_kg: float
    confidence_score: float
    uncertainty_height: float
    uncertainty_weight: float
    processing_time_ms: float
    detection_status: DetectionStatus = DetectionStatus.GOOD_POSITION
    position_message: str = "Ready for measurement"
    stability_frames: int = 0
    is_auto_saved: bool = False
    calibration_quality: float = 0.0

@dataclass
class CameraCalibration:
    camera_matrix: np.ndarray
    dist_coeffs: np.ndarray
    reprojection_error: float
    is_calibrated: bool = False
    calibration_date: str = ""

class EnhancedHeightWeightEstimator:
    """
    Enhanced Height and Weight Estimation System with robust calibration
    Implements advanced computer vision techniques for maximum accuracy
    """
    
    def __init__(self, use_gpu: bool = True, calibration_file: str = "camera_calibration.yaml"):
        self.device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')
        self.calibration_file = calibration_file
        
        # Initialize models and components
        self._initialize_models()
        self._load_or_create_calibration()
        self._initialize_processors()
        
        # Enhanced measurement parameters
        self.auto_save_enabled = True
        self.stability_threshold = 8  # Increased for better stability
        self.max_stability_frames = 15
        self.stability_tolerance_height = 1.0  # cm - tighter tolerance
        self.stability_tolerance_weight = 0.8  # kg - tighter tolerance
        self.auto_save_cooldown = 10.0  # seconds between auto-saves
        
        # Enhanced anthropometric reference values (research-based)
        self.anthropometric_references = {
            'eye_distance_male': 6.4,      # cm - interpupillary distance
            'eye_distance_female': 6.1,    # cm
            'shoulder_width_male': 41.2,   # cm - biacromial breadth
            'shoulder_width_female': 36.8, # cm
            'head_height': 24.1,           # cm - head length
            'face_height': 18.7,           # cm - face height
            'hand_length_male': 18.8,      # cm
            'hand_length_female': 17.1,    # cm
        }
        
        # Enhanced tracking variables
        self.measurement_history = []
        self.confidence_history = []
        self.stability_buffer = []
        self.last_auto_save = 0
        self.consecutive_stable_frames = 0
        
        print(f"Enhanced System initialized on {self.device}")
        print(f"Camera calibration: {'Loaded' if self.camera_calibration.is_calibrated else 'Required'}")
    
    def _initialize_models(self):
        """Initialize all AI models with enhanced configurations"""
        
        # Enhanced Pose Detection with highest accuracy settings
        self.mp_holistic = mp.solutions.holistic.Holistic(
            min_detection_confidence=0.9,  # Increased threshold
            min_tracking_confidence=0.8,   # Increased threshold
            model_complexity=2,             # Highest complexity
            smooth_landmarks=True,
            enable_segmentation=False,
            smooth_segmentation=False,
            refine_face_landmarks=True
        )
        
        # Enhanced Depth Estimation with improved error handling and caching
        self.midas_model = None
        self.midas_transform = None
        model_cache_dir = os.path.join('models', 'midas_cache')
        os.makedirs(model_cache_dir, exist_ok=True)
        
        try:
            # Set up torch hub cache directory
            torch.hub.set_dir(model_cache_dir)
            
            # Try to load DPT model with timeout and proper error handling
            try:
                self.midas_model = torch.hub.load('intel-isl/MiDaS', 'DPT_Large', 
                                                pretrained=True, 
                                                trust_repo=True,
                                                force_reload=False)
                self.midas_transform = torch.hub.load('intel-isl/MiDaS', 
                                                     'transforms', 
                                                     trust_repo=True).dpt_transform
                print("✅ DPT_Large depth model loaded successfully")
            except Exception as e:
                print(f"⚠️ DPT_Large loading failed, falling back to MiDaS: {str(e)}")
                self.midas_model = torch.hub.load('intel-isl/MiDaS', 'MiDaS', 
                                                pretrained=True,
                                                trust_repo=True,
                                                force_reload=False)
                self.midas_transform = torch.hub.load('intel-isl/MiDaS', 
                                                     'transforms',
                                                     trust_repo=True).default_transform
                print("✅ MiDaS base model loaded successfully")
            
            # Move model to device and set to eval mode
            if self.midas_model is not None:
                self.midas_model.to(self.device)
                self.midas_model.eval()
                # Enable half precision for better performance if using GPU
                if self.device.type == 'cuda':
                    self.midas_model = self.midas_model.half()
                
        except Exception as e:
            print(f"⚠️ Warning: Depth estimation will be disabled: {str(e)}")
            self.midas_model = None
            self.midas_transform = None
        
        # Enhanced Weight Estimation Models
        self._initialize_weight_models()
        
        # Face Detection for reference
        self.mp_face_detection = mp.solutions.face_detection.FaceDetection(
            model_selection=1, min_detection_confidence=0.9
        )
    
    def _initialize_weight_models(self):
        """Initialize enhanced weight estimation models"""
        
        # Load or create ensemble weight models
        self.weight_models = {}
        
        # Model 1: Random Forest for anthropometric features
        try:
            self.weight_models['rf'] = joblib.load('models/weight_rf_model.pkl')
            self.weight_scaler = joblib.load('models/weight_scaler.pkl')
            print("✅ Pre-trained weight models loaded")
        except:
            # Create and train basic models if not available
            self._create_basic_weight_models()
            print("✅ Basic weight models created")
    
    def _create_basic_weight_models(self):
        """Create basic weight estimation models"""
        
        # Create a Random Forest model for weight estimation
        self.weight_models['rf'] = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        
        # Create scaler for feature normalization
        self.weight_scaler = StandardScaler()
        
        # Generate synthetic training data for basic functionality
        # In a real implementation, this would use actual anthropometric datasets
        n_samples = 1000
        np.random.seed(42)
        
        # Generate synthetic anthropometric features
        heights = np.random.normal(170, 15, n_samples)  # Height in cm
        genders = np.random.choice([0, 1], n_samples)   # 0=female, 1=male
        
        # Generate correlated features
        features = []
        weights = []
        
        for i in range(n_samples):
            h = heights[i]
            g = genders[i]
            
            # Generate realistic anthropometric ratios
            shoulder_ratio = np.random.normal(0.23 if g else 0.21, 0.02)
            hip_ratio = np.random.normal(0.19 if g else 0.21, 0.02)
            torso_ratio = np.random.normal(0.52, 0.03)
            
            # Create feature vector
            feature_vec = [
                h,  # height
                g,  # gender
                shoulder_ratio * h,  # shoulder width
                hip_ratio * h,       # hip width
                torso_ratio * h,     # torso length
                shoulder_ratio / hip_ratio,  # shoulder-hip ratio
                h * 0.47,  # leg length estimate
                h * 0.18,  # head height estimate
            ]
            
            # Generate realistic weight based on BMI distribution
            if g:  # male
                bmi = np.random.normal(24.5, 3.5)
            else:  # female
                bmi = np.random.normal(23.0, 3.0)
            
            weight = bmi * (h / 100) ** 2
            weight = max(40, min(150, weight))  # Reasonable bounds
            
            features.append(feature_vec)
            weights.append(weight)
        
        features = np.array(features)
        weights = np.array(weights)
        
        # Train the models
        features_scaled = self.weight_scaler.fit_transform(features)
        self.weight_models['rf'].fit(features_scaled, weights)
        
        # Save models
        os.makedirs('models', exist_ok=True)
        joblib.dump(self.weight_models['rf'], 'models/weight_rf_model.pkl')
        joblib.dump(self.weight_scaler, 'models/weight_scaler.pkl')
    
    def _load_or_create_calibration(self):
        """Load existing calibration or create default"""
        
        if os.path.exists(self.calibration_file):
            try:
                with open(self.calibration_file, 'r') as f:
                    calib_data = yaml.safe_load(f)
                
                self.camera_calibration = CameraCalibration(
                    camera_matrix=np.array(calib_data['camera_matrix']),
                    dist_coeffs=np.array(calib_data['dist_coeffs']),
                    reprojection_error=calib_data['reprojection_error'],
                    is_calibrated=calib_data['is_calibrated'],
                    calibration_date=calib_data['calibration_date']
                )
                print(f"✅ Camera calibration loaded (error: {self.camera_calibration.reprojection_error:.3f})")
            except Exception as e:
                print(f"⚠️ Error loading calibration: {e}")
                self._create_default_calibration()
        else:
            self._create_default_calibration()
    
    def _create_default_calibration(self):
        """Create default calibration parameters"""
        
        # Default camera matrix for typical webcam (will be improved by calibration)
        self.camera_calibration = CameraCalibration(
            camera_matrix=np.array([
                [800, 0, 320],
                [0, 800, 240],
                [0, 0, 1]
            ], dtype=np.float32),
            dist_coeffs=np.zeros(5, dtype=np.float32),
            reprojection_error=999.0,  # High error indicates uncalibrated
            is_calibrated=False,
            calibration_date=""
        )
        print("⚠️ Using default camera parameters - calibration recommended")
    
    def _initialize_processors(self):
        """Initialize processing components"""
        self.frame_queue = Queue(maxsize=3)
        self.result_queue = Queue(maxsize=3)
        self.processing_thread = None
        self.is_processing = False
    
    def calibrate_camera(self, video_source=0, num_images=15):
        """
        Perform camera calibration using chessboard pattern
        
        Args:
            video_source: Camera source (0 for default webcam)
            num_images: Number of calibration images to capture
        
        Returns:
            bool: True if calibration successful
        """
        
        print("🎯 Starting camera calibration...")
        print("📋 Instructions:")
        print("   - Hold a chessboard pattern (9x6 squares) in front of the camera")
        print("   - Move it to different positions and angles")
        print("   - Press SPACE to capture calibration images")
        print("   - Press ESC to finish calibration")
        
        # Chessboard parameters
        chessboard_size = (9, 6)  # Internal corners
        square_size = 2.5  # cm - adjust based on your chessboard
        
        # Prepare object points
        objp = np.zeros((chessboard_size[0] * chessboard_size[1], 3), np.float32)
        objp[:, :2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1, 2)
        objp *= square_size
        
        # Arrays to store object points and image points
        objpoints = []  # 3D points in real world space
        imgpoints = []  # 2D points in image plane
        
        cap = cv2.VideoCapture(video_source)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        captured_images = 0
        
        while captured_images < num_images:
            ret, frame = cap.read()
            if not ret:
                print("❌ Error: Could not read frame")
                break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # Find chessboard corners
            ret_corners, corners = cv2.findChessboardCorners(gray, chessboard_size, None)
            
            # Draw the frame
            display_frame = frame.copy()
            
            if ret_corners:
                # Refine corners
                criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
                corners_refined = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
                
                # Draw corners
                cv2.drawChessboardCorners(display_frame, chessboard_size, corners_refined, ret_corners)
                
                # Add status text
                cv2.putText(display_frame, f"Chessboard detected! Press SPACE to capture ({captured_images}/{num_images})", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            else:
                cv2.putText(display_frame, f"Position chessboard in view ({captured_images}/{num_images} captured)", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            cv2.imshow('Camera Calibration', display_frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord(' ') and ret_corners:
                # Capture calibration image
                objpoints.append(objp)
                imgpoints.append(corners_refined)
                captured_images += 1
                print(f"📸 Captured image {captured_images}/{num_images}")
                
                # Brief pause to prevent multiple captures
                time.sleep(0.5)
                
            elif key == 27:  # ESC key
                break
        
        cap.release()
        cv2.destroyAllWindows()
        
        if len(objpoints) < 8:
            print(f"❌ Insufficient calibration images ({len(objpoints)}). Need at least 8.")
            return False
        
        # Perform calibration
        print("🔄 Computing camera calibration...")
        
        ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(
            objpoints, imgpoints, gray.shape[::-1], None, None
        )
        
        if not ret:
            print("❌ Camera calibration failed")
            return False
        
        # Calculate reprojection error
        total_error = 0
        for i in range(len(objpoints)):
            imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], camera_matrix, dist_coeffs)
            error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)
            total_error += error
        
        reprojection_error = total_error / len(objpoints)
        
        # Update calibration
        self.camera_calibration = CameraCalibration(
            camera_matrix=camera_matrix,
            dist_coeffs=dist_coeffs,
            reprojection_error=reprojection_error,
            is_calibrated=True,
            calibration_date=datetime.now().isoformat()
        )
        
        # Save calibration
        self._save_calibration()
        
        print(f"✅ Camera calibration successful!")
        print(f"📊 Reprojection error: {reprojection_error:.3f} pixels")
        print(f"📐 Focal length: fx={camera_matrix[0,0]:.1f}, fy={camera_matrix[1,1]:.1f}")
        print(f"📍 Principal point: cx={camera_matrix[0,2]:.1f}, cy={camera_matrix[1,2]:.1f}")
        
        return True
    
    def _save_calibration(self):
        """Save camera calibration to file"""
        
        calib_data = {
            'camera_matrix': self.camera_calibration.camera_matrix.tolist(),
            'dist_coeffs': self.camera_calibration.dist_coeffs.tolist(),
            'reprojection_error': float(self.camera_calibration.reprojection_error),
            'is_calibrated': self.camera_calibration.is_calibrated,
            'calibration_date': self.camera_calibration.calibration_date
        }
        
        with open(self.calibration_file, 'w') as f:
            yaml.dump(calib_data, f, default_flow_style=False)
        
        print(f"💾 Calibration saved to {self.calibration_file}")
    
    def detect_pose_keypoints(self, frame: np.ndarray) -> Dict:
        """Detect pose keypoints using MediaPipe with enhanced accuracy and robust error handling"""
        
        keypoints = {}
        
        try:
            # Input validation
            if frame is None or frame.size == 0:
                raise ValueError("Invalid input frame")
            
            if len(frame.shape) != 3:
                raise ValueError("Frame must be a 3-channel image")
            
            # Ensure frame is in correct format
            if frame.dtype != np.uint8:
                frame = np.clip(frame, 0, 255).astype(np.uint8)
            
            # Resize large frames for better performance while maintaining accuracy
            max_dimension = 1280
            height, width = frame.shape[:2]
            if max(height, width) > max_dimension:
                scale = max_dimension / max(height, width)
                new_width = int(width * scale)
                new_height = int(height * scale)
                frame = cv2.resize(frame, (new_width, new_height), 
                                 interpolation=cv2.INTER_AREA)
            
            # Undistort frame if camera is calibrated
            if self.camera_calibration.is_calibrated:
                try:
                    frame = cv2.undistort(frame, 
                                        self.camera_calibration.camera_matrix, 
                                        self.camera_calibration.dist_coeffs)
                except Exception as e:
                    print(f"⚠️ Warning: Camera undistortion failed: {str(e)}")
            
            # Enhance image quality for better detection
            # 1. Normalize lighting
            lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            enhanced_frame = cv2.cvtColor(cv2.merge([l, a, b]), cv2.COLOR_LAB2BGR)
            
            # Convert to RGB for MediaPipe
            rgb_frame = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2RGB)
            
            # Holistic detection with timeout protection
            try:
                results = self.mp_holistic.process(rgb_frame)
                
                if results.pose_landmarks:
                    landmarks = []
                    for landmark in results.pose_landmarks.landmark:
                        # Validate landmark values
                        x = np.clip(landmark.x, 0, 1)
                        y = np.clip(landmark.y, 0, 1)
                        v = np.clip(landmark.visibility, 0, 1)
                        
                        landmarks.append([x, y, v])
                    
                    # Validate landmark count
                    if len(landmarks) == 33:  # MediaPipe pose has 33 landmarks
                        keypoints['holistic'] = landmarks
                    else:
                        raise ValueError(f"Invalid landmark count: {len(landmarks)}")
                
                # Enhanced face detection
                face_results = self.mp_face_detection.process(rgb_frame)
                if face_results and face_results.detections:
                    # Filter low-confidence detections
                    valid_detections = [
                        detection for detection in face_results.detections
                        if detection.score[0] > 0.7  # Confidence threshold
                    ]
                    if valid_detections:
                        keypoints['face_detections'] = valid_detections
                
            except Exception as e:
                print(f"⚠️ MediaPipe processing error: {str(e)}")
                return {}
            
            # Validate final keypoints
            if 'holistic' in keypoints:
                # Check for unrealistic landmark positions
                landmarks = np.array(keypoints['holistic'])
                if np.any(np.isnan(landmarks)) or np.any(np.isinf(landmarks)):
                    print("⚠️ Warning: Invalid landmark values detected")
                    return {}
                
                # Verify basic anatomical constraints
                # Example: head should be above hips
                if landmarks[0][1] > landmarks[23][1]:  # nose y > hip y
                    print("⚠️ Warning: Invalid pose detected (anatomically impossible)")
                    return {}
            
        except Exception as e:
            print(f"❌ Pose detection error: {str(e)}")
            return {}
        
        return keypoints
    
    def estimate_depth_enhanced(self, frame: np.ndarray) -> np.ndarray:
        """Enhanced depth estimation with improved metric scaling and robustness"""
        
        try:
            if self.midas_model is None or self.midas_transform is None:
                # Return a reasonable default depth map
                return np.full((frame.shape[0], frame.shape[1]), 2.5, dtype=np.float32)
            
            # Input validation
            if frame.dtype != np.uint8:
                frame = np.clip(frame, 0, 255).astype(np.uint8)
            
            # Ensure frame is in correct format
            if len(frame.shape) == 2:  # Grayscale
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)
            elif frame.shape[2] == 4:  # RGBA
                frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)
            
            # Preprocess frame with error handling
            try:
                input_tensor = self.midas_transform(frame)
                if self.device.type == 'cuda':
                    input_tensor = input_tensor.half()  # Use half precision on GPU
                input_tensor = input_tensor.to(self.device)
                
                with torch.inference_mode():
                    # Process with timeout protection
                    depth = self.midas_model(input_tensor.unsqueeze(0))
                    depth = depth.squeeze().cpu().float().numpy()
                    
                    # Enhanced depth processing pipeline
                    # 1. Remove invalid values
                    depth[~np.isfinite(depth)] = depth[np.isfinite(depth)].mean()
                    
                    # 2. Smooth depth map to reduce noise
                    depth = cv2.GaussianBlur(depth, (5, 5), 0)
                    
                    # 3. Invert depth (MiDaS outputs inverse depth)
                    depth = 1.0 / (depth + 1e-6)
                    
                    # 4. Remove outliers using IQR method
                    q1, q3 = np.percentile(depth, [25, 75])
                    iqr = q3 - q1
                    depth_min = q1 - 1.5 * iqr
                    depth_max = q3 + 1.5 * iqr
                    depth = np.clip(depth, depth_min, depth_max)
                    
                    # 5. Normalize to metric range
                    depth_min, depth_max = np.percentile(depth, [5, 95])
                    depth = np.clip(depth, depth_min, depth_max)
                    depth_range = depth_max - depth_min
                    if depth_range > 0:
                        depth = (depth - depth_min) / depth_range
                    
                    # 6. Scale to metric depth (1.5m to 3.5m range)
                    # Using sigmoid-like scaling for smoother transitions
                    depth = 1.5 + 2.0 * (1 / (1 + np.exp(-4 * (depth - 0.5))))
                    
                    # 7. Apply bilateral filter for edge-preserving smoothing
                    depth = cv2.bilateralFilter(depth.astype(np.float32), 
                                              d=5,  # Diameter of pixel neighborhood
                                              sigmaColor=0.1,  # Filter sigma in color space
                                              sigmaSpace=5)  # Filter sigma in coordinate space
                    
                    # 8. Ensure output is in correct format
                    depth = np.asarray(depth, dtype=np.float32)
                    return depth
                    
            except torch.cuda.OutOfMemoryError:
                print("⚠️ GPU memory exceeded, falling back to CPU")
                torch.cuda.empty_cache()
                if hasattr(self, 'device') and self.device.type == 'cuda':
                    self.device = torch.device('cpu')
                    if self.midas_model is not None:
                        self.midas_model.to(self.device)
                return self.estimate_depth_enhanced(frame)  # Retry on CPU
                
        except Exception as e:
            print(f"⚠️ Depth estimation error: {str(e)}")
            # Return a reasonable default depth map
            return np.full((frame.shape[0], frame.shape[1]), 2.5, dtype=np.float32)
                
        except Exception as e:
            print(f"Depth estimation error: {e}")
            return np.ones((frame.shape[0], frame.shape[1]), dtype=np.float32) * 2.5
    
    def estimate_scale_factor(self, keypoints_2d: Dict, frame_shape: Tuple[int, int]) -> Tuple[float, float]:
        """
        Estimate scale factor using anthropometric references
        
        Returns:
            Tuple[float, float]: (scale_factor_pixels_to_cm, confidence)
        """
        
        if 'holistic' not in keypoints_2d:
            return 0.1, 0.0  # Default scale with no confidence
        
        landmarks = keypoints_2d['holistic']
        height, width = frame_shape
        
        scale_estimates = []
        confidences = []
        
        # Method 1: Eye distance
        try:
            left_eye = landmarks[2]   # Left eye
            right_eye = landmarks[5]  # Right eye
            
            if left_eye[2] > 0.8 and right_eye[2] > 0.8:  # High visibility
                eye_distance_pixels = np.sqrt(
                    ((left_eye[0] - right_eye[0]) * width) ** 2 +
                    ((left_eye[1] - right_eye[1]) * height) ** 2
                )
                
                # Estimate gender from shoulder-hip ratio for reference selection
                if len(landmarks) > 24:
                    left_shoulder = landmarks[11]
                    right_shoulder = landmarks[12]
                    left_hip = landmarks[23]
                    right_hip = landmarks[24]
                    
                    if all(lm[2] > 0.7 for lm in [left_shoulder, right_shoulder, left_hip, right_hip]):
                        shoulder_width = abs(left_shoulder[0] - right_shoulder[0])
                        hip_width = abs(left_hip[0] - right_hip[0])
                        
                        if shoulder_width > 0 and hip_width > 0:
                            shoulder_hip_ratio = shoulder_width / hip_width
                            
                            if shoulder_hip_ratio > 1.0:  # Likely male
                                ref_eye_distance = self.anthropometric_references['eye_distance_male']
                            else:  # Likely female
                                ref_eye_distance = self.anthropometric_references['eye_distance_female']
                            
                            scale_factor = ref_eye_distance / eye_distance_pixels
                            scale_estimates.append(scale_factor)
                            confidences.append(0.9)
        except:
            pass
        
        # Method 2: Shoulder width
        try:
            left_shoulder = landmarks[11]
            right_shoulder = landmarks[12]
            
            if left_shoulder[2] > 0.8 and right_shoulder[2] > 0.8:
                shoulder_distance_pixels = np.sqrt(
                    ((left_shoulder[0] - right_shoulder[0]) * width) ** 2 +
                    ((left_shoulder[1] - right_shoulder[1]) * height) ** 2
                )
                
                # Use average shoulder width as reference
                ref_shoulder_width = (self.anthropometric_references['shoulder_width_male'] + 
                                    self.anthropometric_references['shoulder_width_female']) / 2
                
                scale_factor = ref_shoulder_width / shoulder_distance_pixels
                scale_estimates.append(scale_factor)
                confidences.append(0.7)
        except:
            pass
        
        # Method 3: Head height
        try:
            nose = landmarks[0]
            left_ear = landmarks[7]
            right_ear = landmarks[8]
            
            if nose[2] > 0.8 and left_ear[2] > 0.7 and right_ear[2] > 0.7:
                # Estimate top of head from ear positions
                avg_ear_y = (left_ear[1] + right_ear[1]) / 2
                head_height_pixels = abs(nose[1] - avg_ear_y) * height * 1.3  # Approximate full head
                
                ref_head_height = self.anthropometric_references['head_height']
                scale_factor = ref_head_height / head_height_pixels
                scale_estimates.append(scale_factor)
                confidences.append(0.6)
        except:
            pass
        
        # Combine estimates
        if not scale_estimates:
            return 0.1, 0.0  # Default fallback
        
        # Weighted average
        weights = np.array(confidences)
        weights = weights / np.sum(weights)
        
        final_scale = np.average(scale_estimates, weights=weights)
        final_confidence = np.mean(confidences)
        
        # Sanity check - reasonable scale factors
        if 0.01 <= final_scale <= 1.0:
            return final_scale, final_confidence
        else:
            return 0.1, 0.0
    
    def calculate_3d_keypoints_enhanced(self, keypoints_2d: Dict, depth_map: np.ndarray, 
                                      scale_factor: float) -> Optional[np.ndarray]:
        """Calculate enhanced 3D keypoints with proper camera projection"""
        
        try:
            if 'holistic' not in keypoints_2d:
                return None
            
            landmarks_2d = keypoints_2d['holistic']
            keypoints_3d = []
            
            height, width = depth_map.shape
            
            # Camera parameters
            fx = self.camera_calibration.camera_matrix[0, 0]
            fy = self.camera_calibration.camera_matrix[1, 1]
            cx = self.camera_calibration.camera_matrix[0, 2]
            cy = self.camera_calibration.camera_matrix[1, 2]
            
            for landmark in landmarks_2d:
                x_norm, y_norm, visibility = landmark
                
                if visibility < 0.5:
                    keypoints_3d.append([0, 0, 0])
                    continue
                
                # Convert normalized coordinates to pixel coordinates
                x_pixel = x_norm * width
                y_pixel = y_norm * height
                
                # Ensure coordinates are within bounds
                x_pixel = max(0, min(width - 1, int(x_pixel)))
                y_pixel = max(0, min(height - 1, int(y_pixel)))
                
                # Get depth value (average from small region for robustness)
                region_size = 5
                x_start = max(0, x_pixel - region_size)
                x_end = min(width, x_pixel + region_size)
                y_start = max(0, y_pixel - region_size)
                y_end = min(height, y_pixel + region_size)
                
                depth_region = depth_map[y_start:y_end, x_start:x_end]
                depth_value = np.median(depth_region)  # Use median for robustness
                
                # Convert to 3D coordinates using camera projection
                # Z is depth in meters (converted to cm)
                z_cm = depth_value * 100
                
                # X and Y in cm using camera intrinsics
                x_cm = (x_pixel - cx) * z_cm / fx
                y_cm = (y_pixel - cy) * z_cm / fy
                
                keypoints_3d.append([x_cm, y_cm, z_cm])
            
            return np.array(keypoints_3d)
            
        except Exception as e:
            print(f"3D keypoint calculation error: {e}")
            return None
    
    def estimate_height_enhanced(self, keypoints_3d: Optional[np.ndarray], 
                               keypoints_2d: Dict, scale_factor: float) -> Tuple[float, float]:
        """Enhanced height estimation with multiple methods"""
        
        try:
            if keypoints_3d is None or 'holistic' not in keypoints_2d:
                return 170.0, 0.1
            
            landmarks_2d = keypoints_2d['holistic']
            height_estimates = []
            confidences = []
            
            # Method 1: 3D head to foot distance
            try:
                # Head landmarks (top of head estimated from facial landmarks)
                head_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
                foot_indices = [27, 28, 29, 30, 31, 32]
                
                valid_head = [i for i in head_indices if i < len(landmarks_2d) and landmarks_2d[i][2] > 0.7]
                valid_foot = [i for i in foot_indices if i < len(landmarks_2d) and landmarks_2d[i][2] > 0.7]
                
                if valid_head and valid_foot:
                    head_points = keypoints_3d[valid_head]
                    foot_points = keypoints_3d[valid_foot]
                    
                    # Find highest head point and lowest foot point
                    highest_head_y = np.min(head_points[:, 1])  # Y decreases upward in image
                    lowest_foot_y = np.max(foot_points[:, 1])
                    
                    height_3d = abs(lowest_foot_y - highest_head_y)
                    
                    # Add head top estimation (approximately 12cm above nose)
                    height_3d += 12.0
                    
                    if 140 <= height_3d <= 220:
                        height_estimates.append(height_3d)
                        confidences.append(0.9)
            except:
                pass
            
            # Method 2: Proportional estimation using body segments
            try:
                # Use known body proportions
                shoulder_center_idx = 11  # Approximate shoulder center
                hip_center_idx = 23      # Approximate hip center
                ankle_idx = 27           # Ankle
                
                if (shoulder_center_idx < len(landmarks_2d) and 
                    hip_center_idx < len(landmarks_2d) and 
                    ankle_idx < len(landmarks_2d)):
                    
                    shoulder_vis = landmarks_2d[shoulder_center_idx][2]
                    hip_vis = landmarks_2d[hip_center_idx][2]
                    ankle_vis = landmarks_2d[ankle_idx][2]
                    
                    if shoulder_vis > 0.7 and hip_vis > 0.7 and ankle_vis > 0.7:
                        shoulder_y = keypoints_3d[shoulder_center_idx][1]
                        hip_y = keypoints_3d[hip_center_idx][1]
                        ankle_y = keypoints_3d[ankle_idx][1]
                        
                        # Calculate body segments
                        torso_length = abs(shoulder_y - hip_y)
                        leg_length = abs(hip_y - ankle_y)
                        
                        # Estimate total height using anthropometric proportions
                        # Head: ~13% of height, Torso: ~30%, Legs: ~57%
                        if torso_length > 0:
                            estimated_height = torso_length / 0.30
                        elif leg_length > 0:
                            estimated_height = leg_length / 0.57
                        else:
                            estimated_height = 170.0
                        
                        if 140 <= estimated_height <= 220:
                            height_estimates.append(estimated_height)
                            confidences.append(0.7)
            except:
                pass
            
            # Method 3: 2D pixel-based with scale factor (fallback)
            try:
                head_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
                foot_indices = [27, 28, 29, 30, 31, 32]
                
                valid_head = [i for i in head_indices if i < len(landmarks_2d) and landmarks_2d[i][2] > 0.6]
                valid_foot = [i for i in foot_indices if i < len(landmarks_2d) and landmarks_2d[i][2] > 0.6]
                
                if valid_head and valid_foot and scale_factor > 0:
                    head_y = min([landmarks_2d[i][1] for i in valid_head])
                    foot_y = max([landmarks_2d[i][1] for i in valid_foot])
                    
                    height_pixels = abs(foot_y - head_y) * 720  # Assuming 720p height
                    height_2d = height_pixels * scale_factor
                    
                    if 140 <= height_2d <= 220:
                        height_estimates.append(height_2d)
                        confidences.append(0.6)
            except:
                pass
            
            # Combine estimates
            if not height_estimates:
                return 170.0, 0.1
            
            # Remove outliers using IQR method
            if len(height_estimates) > 2:
                q1 = np.percentile(height_estimates, 25)
                q3 = np.percentile(height_estimates, 75)
                iqr = q3 - q1
                lower_bound = q1 - 1.5 * iqr
                upper_bound = q3 + 1.5 * iqr
                
                filtered_estimates = []
                filtered_confidences = []
                
                for est, conf in zip(height_estimates, confidences):
                    if lower_bound <= est <= upper_bound:
                        filtered_estimates.append(est)
                        filtered_confidences.append(conf)
                
                if filtered_estimates:
                    height_estimates = filtered_estimates
                    confidences = filtered_confidences
            
            # Weighted average
            weights = np.array(confidences)
            weights = weights / np.sum(weights)
            
            final_height = np.average(height_estimates, weights=weights)
            final_confidence = np.mean(confidences)
            
            # Temporal smoothing
            self.measurement_history.append(final_height)
            if len(self.measurement_history) > 10:
                self.measurement_history.pop(0)
            
            if len(self.measurement_history) >= 5:
                # Use exponential moving average
                alpha = 0.3
                smoothed_height = self.measurement_history[0]
                for h in self.measurement_history[1:]:
                    smoothed_height = alpha * h + (1 - alpha) * smoothed_height
                
                final_height = smoothed_height
                
                # Boost confidence for consistent measurements
                height_std = np.std(self.measurement_history[-5:])
                if height_std < 2.0:
                    final_confidence = min(0.95, final_confidence * 1.2)
            
            return final_height, final_confidence
            
        except Exception as e:
            print(f"Height estimation error: {e}")
            return 170.0, 0.1
    
    def extract_anthropometric_features_enhanced(self, keypoints_3d: Optional[np.ndarray], 
                                               height: float) -> np.ndarray:
        """Extract enhanced anthropometric features for weight estimation"""
        
        features = np.zeros(20)  # Reduced feature set for stability
        
        if keypoints_3d is not None and len(keypoints_3d) > 32:
            try:
                # Basic landmarks
                left_shoulder = keypoints_3d[11]
                right_shoulder = keypoints_3d[12]
                left_hip = keypoints_3d[23]
                right_hip = keypoints_3d[24]
                left_knee = keypoints_3d[25]
                right_knee = keypoints_3d[26]
                left_ankle = keypoints_3d[27]
                right_ankle = keypoints_3d[28]
                
                # Calculate measurements
                shoulder_width = np.linalg.norm(left_shoulder - right_shoulder)
                hip_width = np.linalg.norm(left_hip - right_hip)
                
                shoulder_center = (left_shoulder + right_shoulder) / 2
                hip_center = (left_hip + right_hip) / 2
                knee_center = (left_knee + right_knee) / 2
                ankle_center = (left_ankle + right_ankle) / 2
                
                torso_length = np.linalg.norm(shoulder_center - hip_center)
                thigh_length = np.linalg.norm(hip_center - knee_center)
                calf_length = np.linalg.norm(knee_center - ankle_center)
                
                # Populate features
                if height > 0:
                    features[0] = height  # Height in cm
                    features[1] = shoulder_width / height * 100  # Shoulder width ratio
                    features[2] = hip_width / height * 100       # Hip width ratio
                    features[3] = torso_length / height * 100    # Torso ratio
                    features[4] = (thigh_length + calf_length) / height * 100  # Leg ratio
                
                # Absolute measurements
                features[5] = shoulder_width
                features[6] = hip_width
                features[7] = torso_length
                
                # Body shape indicators
                if shoulder_width > 0 and hip_width > 0:
                    features[8] = hip_width / shoulder_width  # Hip-shoulder ratio
                
                if torso_length > 0:
                    features[9] = shoulder_width / torso_length
                    features[10] = hip_width / torso_length
                
                # Volume estimates (simplified)
                torso_volume = shoulder_width * hip_width * torso_length
                features[11] = torso_volume
                
                # Additional ratios
                features[12] = thigh_length
                features[13] = calf_length
                
                if thigh_length > 0 and calf_length > 0:
                    features[14] = thigh_length / calf_length
                
                # Gender estimation (simplified)
                if shoulder_width > 0 and hip_width > 0:
                    shoulder_hip_ratio = shoulder_width / hip_width
                    features[15] = 1.0 if shoulder_hip_ratio > 1.0 else 0.0  # Male=1, Female=0
                
                # Body mass distribution indicators
                features[16] = shoulder_width * torso_length  # Upper body area
                features[17] = hip_width * (thigh_length + calf_length)  # Lower body area
                
                # Proportionality indicators
                if height > 0:
                    features[18] = (shoulder_width + hip_width) / 2 / height * 100
                    features[19] = torso_length / (thigh_length + calf_length) if (thigh_length + calf_length) > 0 else 1.0
                
            except Exception as e:
                print(f"Feature extraction error: {e}")
        
        return features
    
    def estimate_weight_enhanced(self, anthropometric_features: np.ndarray, 
                               height: float) -> Tuple[float, float]:
        """Enhanced weight estimation using ensemble methods"""
        
        try:
            weight_estimates = []
            confidences = []
            
            # Method 1: Machine Learning Model
            try:
                if len(anthropometric_features) >= 8:
                    # Prepare features for ML model
                    ml_features = anthropometric_features[:8].reshape(1, -1)
                    ml_features_scaled = self.weight_scaler.transform(ml_features)
                    
                    # Predict weight
                    weight_ml = self.weight_models['rf'].predict(ml_features_scaled)[0]
                    
                    if 40 <= weight_ml <= 150:
                        weight_estimates.append(weight_ml)
                        confidences.append(0.8)
            except Exception as e:
                print(f"ML weight estimation error: {e}")
            
            # Method 2: Enhanced BMI-based estimation
            try:
                if height > 0:
                    # Estimate BMI based on body type
                    shoulder_hip_ratio = anthropometric_features[8] if len(anthropometric_features) > 8 else 0.9
                    
                    # Adjust BMI based on body type
                    if shoulder_hip_ratio < 0.8:  # Pear shape
                        base_bmi = 22.5
                    elif shoulder_hip_ratio > 1.1:  # Athletic/broad shoulders
                        base_bmi = 24.5
                    else:  # Average build
                        base_bmi = 23.0
                    
                    # Height adjustments
                    if height > 180:
                        base_bmi += 0.5
                    elif height < 160:
                        base_bmi -= 0.5
                    
                    height_m = height / 100
                    weight_bmi = base_bmi * (height_m ** 2)
                    
                    if 40 <= weight_bmi <= 150:
                        weight_estimates.append(weight_bmi)
                        confidences.append(0.7)
            except:
                pass
            
            # Method 3: Anthropometric formula (Robinson-based)
            try:
                if height > 0:
                    height_inches = height / 2.54
                    
                    # Gender estimation
                    is_male = anthropometric_features[15] if len(anthropometric_features) > 15 else 0.5
                    
                    if is_male > 0.5:  # Male
                        weight_robinson = 52 + 1.9 * (height_inches - 60)
                    else:  # Female
                        weight_robinson = 49 + 1.7 * (height_inches - 60)
                    
                    # Frame size adjustment
                    if len(anthropometric_features) > 5:
                        shoulder_width = anthropometric_features[5]
                        if shoulder_width > 45:  # Large frame
                            weight_robinson *= 1.08
                        elif shoulder_width < 35:  # Small frame
                            weight_robinson *= 0.92
                    
                    if 40 <= weight_robinson <= 150:
                        weight_estimates.append(weight_robinson)
                        confidences.append(0.6)
            except:
                pass
            
            # Fallback method
            if not weight_estimates:
                height_m = height / 100 if height > 0 else 1.7
                fallback_weight = 22.5 * (height_m ** 2)  # Average BMI
                weight_estimates.append(fallback_weight)
                confidences.append(0.3)
            
            # Combine estimates
            weights_array = np.array(confidences)
            weights_array = weights_array / np.sum(weights_array)
            
            final_weight = np.average(weight_estimates, weights=weights_array)
            final_confidence = np.mean(confidences)
            
            # Bounds checking
            final_weight = max(40, min(150, final_weight))
            
            return final_weight, final_confidence
            
        except Exception as e:
            print(f"Weight estimation error: {e}")
            return 70.0, 0.3
    
    def process_frame_enhanced(self, frame: np.ndarray) -> MeasurementResult:
        """Enhanced frame processing with all improvements"""
        
        start_time = time.time()
        
        # Detect pose keypoints
        keypoints_2d = self.detect_pose_keypoints(frame)
        
        # Check if human is detected and body is complete
        detection_status, position_message, body_parts = self.check_complete_body_visibility(
            keypoints_2d, frame.shape[:2]
        )
        
        if detection_status in [DetectionStatus.NO_HUMAN, DetectionStatus.PARTIAL_BODY]:
            processing_time = (time.time() - start_time) * 1000
            return MeasurementResult(
                height_cm=0.0,
                weight_kg=0.0,
                confidence_score=0.0,
                uncertainty_height=999.0,
                uncertainty_weight=999.0,
                processing_time_ms=processing_time,
                detection_status=detection_status,
                position_message=position_message,
                calibration_quality=self.camera_calibration.reprojection_error if self.camera_calibration.is_calibrated else 999.0
            )
        
        # Estimate depth
        depth_map = self.estimate_depth_enhanced(frame)
        
        # Estimate scale factor
        scale_factor, scale_confidence = self.estimate_scale_factor(keypoints_2d, frame.shape[:2])
        
        # Calculate 3D keypoints
        keypoints_3d = self.calculate_3d_keypoints_enhanced(keypoints_2d, depth_map, scale_factor)
        
        # Estimate height
        height, height_confidence = self.estimate_height_enhanced(keypoints_3d, keypoints_2d, scale_factor)
        
        # Extract anthropometric features
        anthropometric_features = self.extract_anthropometric_features_enhanced(keypoints_3d, height)
        
        # Estimate weight
        weight, weight_confidence = self.estimate_weight_enhanced(anthropometric_features, height)
        
        # Calculate overall confidence
        overall_confidence = self.calculate_confidence_enhanced(
            scale_confidence, height_confidence, weight_confidence, height, weight
        )
        
        # Calculate uncertainties
        uncertainty_height = max(1.0, 5.0 * (1.0 - height_confidence))
        uncertainty_weight = max(2.0, 8.0 * (1.0 - weight_confidence))
        
        processing_time = (time.time() - start_time) * 1000
        
        result = MeasurementResult(
            height_cm=height,
            weight_kg=weight,
            confidence_score=overall_confidence,
            uncertainty_height=uncertainty_height,
            uncertainty_weight=uncertainty_weight,
            processing_time_ms=processing_time,
            detection_status=DetectionStatus.GOOD_POSITION,
            position_message="✅ MEASURING - Hold steady for accurate results",
            calibration_quality=self.camera_calibration.reprojection_error if self.camera_calibration.is_calibrated else 999.0
        )
        
        # Check for auto-save stability
        return self.check_measurement_stability_enhanced(result)
    
    def calculate_confidence_enhanced(self, scale_confidence: float, height_confidence: float, 
                                    weight_confidence: float, height: float, weight: float) -> float:
        """Calculate enhanced overall confidence score"""
        
        try:
            # Base confidence from individual components
            base_confidence = (scale_confidence * 0.3 + height_confidence * 0.4 + weight_confidence * 0.3)
            
            # Calibration quality factor
            if self.camera_calibration.is_calibrated:
                if self.camera_calibration.reprojection_error < 0.5:
                    calib_factor = 1.0
                elif self.camera_calibration.reprojection_error < 1.0:
                    calib_factor = 0.9
                else:
                    calib_factor = 0.8
            else:
                calib_factor = 0.6  # Penalty for uncalibrated camera
            
            # Reasonableness checks
            height_reasonable = 1.0 if 140 <= height <= 220 else 0.7
            weight_reasonable = 1.0 if 40 <= weight <= 150 else 0.7
            
            # BMI reasonableness
            if height > 0:
                bmi = weight / ((height / 100) ** 2)
                bmi_reasonable = 1.0 if 16 <= bmi <= 40 else 0.8
            else:
                bmi_reasonable = 0.5
            
            # Combine all factors
            final_confidence = (base_confidence * calib_factor * 
                              height_reasonable * weight_reasonable * bmi_reasonable)
            
            # Temporal consistency bonus
            self.confidence_history.append(final_confidence)
            if len(self.confidence_history) > 10:
                self.confidence_history.pop(0)
            
            if len(self.confidence_history) >= 5:
                confidence_std = np.std(self.confidence_history[-5:])
                if confidence_std < 0.05:
                    final_confidence = min(0.95, final_confidence * 1.15)
                elif confidence_std < 0.1:
                    final_confidence = min(0.90, final_confidence * 1.08)
            
            return max(0.1, min(0.95, final_confidence))
            
        except Exception as e:
            print(f"Confidence calculation error: {e}")
            return 0.5
    
    def check_complete_body_visibility(self, keypoints_2d: Dict, frame_shape: Tuple[int, int]) -> Tuple[DetectionStatus, str, Dict[str, bool]]:
        """Enhanced body visibility check"""
        
        if 'holistic' not in keypoints_2d or len(keypoints_2d['holistic']) < 33:
            return DetectionStatus.NO_HUMAN, "❌ HUMAN NOT DETECTED - Please stand in front of camera", {}
        
        landmarks = keypoints_2d['holistic']
        visibility_threshold = 0.7
        
        # Check essential body parts
        body_parts = {
            'head': False,
            'shoulders': False,
            'arms': False,
            'torso': False,
            'hips': False,
            'legs': False,
            'feet': False
        }
        
        missing_parts = []
        
        # Head (nose, eyes, ears)
        head_landmarks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        head_visible = sum(1 for i in head_landmarks if landmarks[i][2] > visibility_threshold)
        body_parts['head'] = head_visible >= 6
        if not body_parts['head']:
            missing_parts.append("HEAD")
        
        # Shoulders
        shoulder_landmarks = [11, 12]
        shoulders_visible = sum(1 for i in shoulder_landmarks if landmarks[i][2] > visibility_threshold)
        body_parts['shoulders'] = shoulders_visible >= 2
        if not body_parts['shoulders']:
            missing_parts.append("SHOULDERS")
        
        # Arms
        arm_landmarks = [13, 14, 15, 16]
        arms_visible = sum(1 for i in arm_landmarks if landmarks[i][2] > visibility_threshold)
        body_parts['arms'] = arms_visible >= 3
        if not body_parts['arms']:
            missing_parts.append("ARMS")
        
        # Torso (shoulders to hips)
        torso_landmarks = [11, 12, 23, 24]
        torso_visible = sum(1 for i in torso_landmarks if landmarks[i][2] > visibility_threshold)
        body_parts['torso'] = torso_visible >= 4
        if not body_parts['torso']:
            missing_parts.append("TORSO")
        
        # Hips
        hip_landmarks = [23, 24]
        hips_visible = sum(1 for i in hip_landmarks if landmarks[i][2] > visibility_threshold)
        body_parts['hips'] = hips_visible >= 2
        if not body_parts['hips']:
            missing_parts.append("HIPS")
        
        # Legs
        leg_landmarks = [25, 26, 27, 28]
        legs_visible = sum(1 for i in leg_landmarks if landmarks[i][2] > visibility_threshold)
        body_parts['legs'] = legs_visible >= 3
        if not body_parts['legs']:
            missing_parts.append("LEGS")
        
        # Feet
        feet_landmarks = [27, 28, 29, 30, 31, 32]
        feet_visible = sum(1 for i in feet_landmarks if landmarks[i][2] > visibility_threshold)
        body_parts['feet'] = feet_visible >= 4
        if not body_parts['feet']:
            missing_parts.append("FEET")
        
        if missing_parts:
            message = f"⚠️ ADJUST POSITION - Missing: {', '.join(missing_parts)}"
            return DetectionStatus.PARTIAL_BODY, message, body_parts
        
        # All parts visible - check positioning
        head_y = min(landmarks[i][1] for i in head_landmarks if landmarks[i][2] > visibility_threshold)
        feet_y = max(landmarks[i][1] for i in feet_landmarks if landmarks[i][2] > visibility_threshold)
        
        if head_y > 0.15:
            return DetectionStatus.PARTIAL_BODY, "⚠️ MOVE BACK - Head not fully visible", body_parts
        
        if feet_y < 0.85:
            return DetectionStatus.PARTIAL_BODY, "⚠️ MOVE BACK - Feet not fully visible", body_parts
        
        return DetectionStatus.GOOD_POSITION, "✅ PERFECT POSITION - All body parts visible", body_parts
    
    def check_measurement_stability_enhanced(self, current_result: MeasurementResult) -> MeasurementResult:
        """Enhanced measurement stability check for auto-save"""
        
        current_time = time.time()
        
        # Add current measurement to stability buffer
        self.stability_buffer.append({
            'height': current_result.height_cm,
            'weight': current_result.weight_kg,
            'confidence': current_result.confidence_score,
            'timestamp': current_time
        })
        
        # Keep only recent measurements
        self.stability_buffer = [
            m for m in self.stability_buffer 
            if current_time - m['timestamp'] <= 5.0
        ]
        
        if len(self.stability_buffer) < self.stability_threshold:
            frames_needed = self.stability_threshold - len(self.stability_buffer)
            current_result.position_message = f"📊 MEASURING - Need {frames_needed} more stable readings"
            current_result.detection_status = DetectionStatus.MEASURING_STABLE
            current_result.stability_frames = len(self.stability_buffer)
            return current_result
        
        # Check stability
        recent_measurements = self.stability_buffer[-self.stability_threshold:]
        
        heights = [m['height'] for m in recent_measurements]
        weights = [m['weight'] for m in recent_measurements]
        confidences = [m['confidence'] for m in recent_measurements]
        
        height_range = max(heights) - min(heights)
        weight_range = max(weights) - min(weights)
        avg_confidence = np.mean(confidences)
        
        height_stable = height_range <= self.stability_tolerance_height
        weight_stable = weight_range <= self.stability_tolerance_weight
        confidence_high = avg_confidence > 0.8
        
        if height_stable and weight_stable and confidence_high:
            self.consecutive_stable_frames += 1
            
            if (self.consecutive_stable_frames >= self.max_stability_frames and 
                self.auto_save_enabled and 
                current_time - self.last_auto_save > self.auto_save_cooldown):
                
                # Auto-save measurement
                avg_height = np.mean(heights)
                avg_weight = np.mean(weights)
                height_std = np.std(heights)
                weight_std = np.std(weights)
                
                final_result = MeasurementResult(
                    height_cm=avg_height,
                    weight_kg=avg_weight,
                    confidence_score=avg_confidence,
                    uncertainty_height=max(0.5, height_std),
                    uncertainty_weight=max(1.0, weight_std),
                    processing_time_ms=current_result.processing_time_ms,
                    detection_status=DetectionStatus.AUTO_SAVED,
                    position_message="🎉 MEASUREMENT SAVED! - High accuracy achieved",
                    stability_frames=self.consecutive_stable_frames,
                    is_auto_saved=True,
                    calibration_quality=current_result.calibration_quality
                )
                
                self._save_measurement_enhanced(final_result, auto_save=True)
                self.last_auto_save = current_time
                self.stability_buffer.clear()
                self.consecutive_stable_frames = 0
                
                return final_result
            else:
                current_result.position_message = f"📊 STABLE - {self.consecutive_stable_frames}/{self.max_stability_frames} frames"
                current_result.detection_status = DetectionStatus.MEASURING_STABLE
                current_result.stability_frames = self.consecutive_stable_frames
        else:
            self.consecutive_stable_frames = 0
            current_result.position_message = "📊 MEASURING - Hold steady for accurate results"
            current_result.detection_status = DetectionStatus.MEASURING_STABLE
        
        current_result.stability_frames = len(self.stability_buffer)
        return current_result
    
    def _save_measurement_enhanced(self, result: MeasurementResult, auto_save: bool = False):
        """Save enhanced measurement with comprehensive data and validation"""
        
        try:
            # Input validation
            if not isinstance(result, MeasurementResult):
                raise ValueError("Invalid measurement result type")
            
            if result.height_cm <= 0 or result.weight_kg <= 0:
                raise ValueError("Invalid height or weight values")
            
            # Calculate BMI and health metrics with proper error handling
            height_m = result.height_cm / 100
            
            # Validate height range (typically 0.5m to 2.5m)
            if not 0.5 <= height_m <= 2.5:
                raise ValueError(f"Height {height_m}m is outside reasonable range")
            
            # Calculate BMI with validation
            bmi = result.weight_kg / (height_m ** 2)
            
            # Validate BMI range (typically 10 to 60)
            if not 10 <= bmi <= 60:
                raise ValueError(f"Calculated BMI {bmi} is outside reasonable range")
            
            # Enhanced BMI categorization with age/gender considerations
            # Note: This is a simplified version, could be expanded based on age/gender
            if bmi < 16:
                bmi_category = "Severe Underweight"
                health_risk = "Very High"
            elif bmi < 18.5:
                bmi_category = "Underweight"
                health_risk = "Moderate"
            elif bmi < 25:
                bmi_category = "Normal Weight"
                health_risk = "Low"
            elif bmi < 30:
                bmi_category = "Overweight"
                health_risk = "Moderate"
            elif bmi < 35:
                bmi_category = "Obese Class I"
                health_risk = "High"
            elif bmi < 40:
                bmi_category = "Obese Class II"
                health_risk = "Very High"
            else:
                bmi_category = "Obese Class III"
                health_risk = "Extremely High"
            
            # Calculate ideal weight range using improved formula
            # Using both BMI method and improved Hamwi formula
            ideal_weight_bmi_min = 18.5 * (height_m ** 2)
            ideal_weight_bmi_max = 24.9 * (height_m ** 2)
            
            height_inches = result.height_cm / 2.54
            base_weight = 48 + 2.7 * (height_inches - 60)  # Base Hamwi formula
            
            # Combine both methods with weighted average
            ideal_weight_min = (ideal_weight_bmi_min * 0.7 + base_weight * 0.3)
            ideal_weight_max = (ideal_weight_bmi_max * 0.7 + (base_weight * 1.1) * 0.3)
            
            # Calculate weight difference from ideal range midpoint
            weight_difference = result.weight_kg - ((ideal_weight_min + ideal_weight_max) / 2)
            
            # Validate final calculations
            if not 20 <= ideal_weight_min <= 120:
                raise ValueError(f"Calculated ideal weight minimum {ideal_weight_min} is outside reasonable range")
            if not 30 <= ideal_weight_max <= 150:
                raise ValueError(f"Calculated ideal weight maximum {ideal_weight_max} is outside reasonable range")
            
        except Exception as e:
            print(f"⚠️ Error in measurement calculations: {str(e)}")
            # Set safe default values
            bmi = 0
            bmi_category = "Error in Calculation"
            health_risk = "Unknown"
            ideal_weight_min = 0
            ideal_weight_max = 0
            weight_difference = 0
        
        # Create measurement data
        measurement_data = {
            'timestamp': datetime.now().isoformat(),
            'measurement_id': f"HW_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]}",
            
            # Core measurements
            'height_cm': round(result.height_cm, 2),
            'weight_kg': round(result.weight_kg, 2),
            'bmi': round(bmi, 2),
            'bmi_category': bmi_category,
            'health_risk_level': health_risk,
            
            # Quality metrics
            'confidence_score': round(result.confidence_score, 4),
            'measurement_quality': 'Excellent' if result.confidence_score > 0.9 else 'High' if result.confidence_score > 0.8 else 'Good' if result.confidence_score > 0.7 else 'Fair',
            'uncertainty_height_cm': round(result.uncertainty_height, 2),
            'uncertainty_weight_kg': round(result.uncertainty_weight, 2),
            'calibration_quality': round(result.calibration_quality, 3),
            'camera_calibrated': self.camera_calibration.is_calibrated,
            
            # Processing metrics
            'processing_time_ms': round(result.processing_time_ms, 1),
            'stability_frames_analyzed': result.stability_frames,
            'detection_status': result.detection_status.value,
            'auto_saved': auto_save,
            
            # Health analysis
            'ideal_weight_range_kg': {
                'min': round(ideal_weight_min, 1),
                'max': round(ideal_weight_max, 1)
            },
            'weight_difference_kg': round(weight_difference, 1),
            'weight_status': 'Above ideal' if weight_difference > 2 else 'Below ideal' if weight_difference < -2 else 'Within ideal range',
            
            # System information
            'system_version': '3.0_enhanced',
            'accuracy_target': 'Maximum achievable with single camera',
            'measurement_method': 'Enhanced multi-modal anthropometric analysis',
            'validation_level': 'Research-grade with uncertainty quantification'
        }
        
        # Save to file
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
        prefix = "AUTO_" if auto_save else "MANUAL_"
        filename = f"{prefix}measurement_{timestamp}.json"
        
        try:
            os.makedirs('measurements', exist_ok=True)
            filepath = os.path.join('measurements', filename)
            
            with open(filepath, 'w') as f:
                json.dump(measurement_data, f, indent=2)
            
            # Print save confirmation
            save_type = "🤖 AUTO-SAVED" if auto_save else "💾 MANUALLY SAVED"
            print(f"\n{save_type} MEASUREMENT:")
            print(f"📁 File: {filename}")
            print(f"📏 Height: {result.height_cm:.1f} ± {result.uncertainty_height:.1f} cm")
            print(f"⚖️  Weight: {result.weight_kg:.1f} ± {result.uncertainty_weight:.1f} kg")
            print(f"📊 BMI: {bmi:.1f} ({bmi_category})")
            print(f"🎯 Accuracy: {result.confidence_score:.1%} ({measurement_data['measurement_quality']})")
            print(f"📐 Calibration: {'✅ Calibrated' if self.camera_calibration.is_calibrated else '⚠️ Uncalibrated'}")
            
        except IOError as e:
            print(f"❌ Error saving measurement: {e}")
    
    def start_enhanced_real_time_processing(self, video_source=0):
        """Start enhanced real-time processing with improved camera initialization"""
        
        # Check calibration status
        if not self.camera_calibration.is_calibrated:
            print("⚠️ Camera not calibrated. For best accuracy, run calibration first.")
            response = input("Do you want to calibrate now? (y/n): ").lower().strip()
            if response == 'y':
                if self.calibrate_camera(video_source):
                    print("✅ Calibration complete. Starting measurement system...")
                else:
                    print("⚠️ Calibration failed. Continuing with default parameters...")
            else:
                print("⚠️ Continuing with uncalibrated camera. Accuracy may be reduced.")
        
        # Initialize camera with proper error handling
        max_retries = 3
        cap = None
        
        for attempt in range(max_retries):
            try:
                cap = cv2.VideoCapture(video_source)
                if not cap.isOpened():
                    raise RuntimeError("Failed to open camera")
                
                # Set camera properties with verification
                target_width = 1280
                target_height = 720
                target_fps = 30
                
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, target_width)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, target_height)
                cap.set(cv2.CAP_PROP_FPS, target_fps)
                
                # Verify camera settings
                actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                actual_fps = int(cap.get(cv2.CAP_PROP_FPS))
                
                if abs(actual_width - target_width) > 100 or abs(actual_height - target_height) > 100:
                    print(f"⚠️ Warning: Camera resolution differs from requested: {actual_width}x{actual_height}")
                if abs(actual_fps - target_fps) > 5:
                    print(f"⚠️ Warning: Camera FPS differs from requested: {actual_fps}")
                
                # Set additional camera properties for better quality
                cap.set(cv2.CAP_PROP_AUTOFOCUS, 1)  # Enable autofocus
                cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 1)  # Enable auto exposure
                
                print(f"✅ Camera initialized successfully: {actual_width}x{actual_height} @ {actual_fps}fps")
                break
                
            except Exception as e:
                print(f"❌ Camera initialization attempt {attempt + 1} failed: {str(e)}")
                if cap is not None:
                    cap.release()
                if attempt == max_retries - 1:
                    raise RuntimeError(f"Failed to initialize camera after {max_retries} attempts")
        
        if not cap.isOpened():
            print("❌ Error: Could not open camera")
            return
        
        print("🚀 Enhanced Real-time Processing Started")
        print("📋 Controls:")
        print("   'q' - Quit application")
        print("   's' - Manual save current measurement")
        print("   'r' - Reset stability buffer")
        print("   'c' - Toggle auto-save")
        print("   'k' - Recalibrate camera")
        print("🤖 Auto-save will trigger when measurements are stable")
        print("=" * 60)
        
        # Create window
        cv2.namedWindow('Enhanced Height & Weight Estimation', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Enhanced Height & Weight Estimation', 1280, 720)
        
        measurements_history = []
        fps_counter = 0
        fps_start_time = time.time()
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("❌ Error: Could not read frame from camera")
                    break
                
                # Process frame
                try:
                    result = self.process_frame_enhanced(frame)
                    measurements_history.append(result)
                    
                    if len(measurements_history) > 10:
                        measurements_history.pop(0)
                    
                    # Draw results
                    self._draw_enhanced_results(frame, result, measurements_history)
                    
                except Exception as e:
                    print(f"❌ Processing error: {e}")
                    cv2.putText(frame, "Processing Error - Check Console", (50, 50), 
                              cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
                # Performance monitoring
                fps_counter += 1
                if fps_counter % 30 == 0:
                    fps_end_time = time.time()
                    current_fps = 30 / (fps_end_time - fps_start_time)
                    fps_start_time = fps_end_time
                    print(f"⚡ FPS: {current_fps:.1f}")
                
                # Display frame
                cv2.imshow('Enhanced Height & Weight Estimation', frame)
                
                # Handle keyboard input
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("👋 Shutting down...")
                    break
                elif key == ord('s') and measurements_history:
                    latest = measurements_history[-1]
                    if latest.detection_status == DetectionStatus.GOOD_POSITION:
                        self._save_measurement_enhanced(latest, auto_save=False)
                    else:
                        print("⚠️ Cannot save - No valid measurement available")
                elif key == ord('r'):
                    self.stability_buffer.clear()
                    self.consecutive_stable_frames = 0
                    print("🔄 Stability buffer reset")
                elif key == ord('c'):
                    self.auto_save_enabled = not self.auto_save_enabled
                    status = "ON" if self.auto_save_enabled else "OFF"
                    print(f"🤖 Auto-save toggled: {status}")
                elif key == ord('k'):
                    print("🎯 Starting camera recalibration...")
                    cap.release()
                    cv2.destroyAllWindows()
                    if self.calibrate_camera(video_source):
                        print("✅ Recalibration complete")
                    # Reinitialize camera
                    cap = cv2.VideoCapture(video_source)
                    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
                    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
                    cap.set(cv2.CAP_PROP_FPS, 30)
                    cv2.namedWindow('Enhanced Height & Weight Estimation', cv2.WINDOW_NORMAL)
                    cv2.resizeWindow('Enhanced Height & Weight Estimation', 1280, 720)
        
        except KeyboardInterrupt:
            print("\n⛔ Interrupted by user")
        
        finally:
            cap.release()
            cv2.destroyAllWindows()
            print("🔚 Camera and windows closed")
    
    def _draw_enhanced_results(self, frame: np.ndarray, result: MeasurementResult, 
                             history: List[MeasurementResult]):
        """Enhanced result display with comprehensive information"""
        
        height, width = frame.shape[:2]
        
        # Handle different detection statuses
        if result.detection_status == DetectionStatus.NO_HUMAN:
            self._draw_no_human_detected(frame, result)
            return
        elif result.detection_status == DetectionStatus.PARTIAL_BODY:
            self._draw_partial_body_detected(frame, result)
            return
        
        # Normal measurement display
        overlay = frame.copy()
        
        # Get smoothed values from history
        valid_history = [m for m in history if m.detection_status not in [DetectionStatus.NO_HUMAN, DetectionStatus.PARTIAL_BODY]]
        
        if len(valid_history) >= 3:
            recent_heights = [m.height_cm for m in valid_history[-5:]]
            recent_weights = [m.weight_kg for m in valid_history[-5:]]
            recent_confidences = [m.confidence_score for m in valid_history[-3:]]
            
            display_height = np.median(recent_heights)
            display_weight = np.median(recent_weights)
            display_confidence = np.mean(recent_confidences)
        else:
            display_height = result.height_cm
            display_weight = result.weight_kg
            display_confidence = result.confidence_score
        
        # Color scheme based on status and confidence
        if result.detection_status == DetectionStatus.AUTO_SAVED:
            primary_color = (0, 255, 0)
            bg_color = (0, 80, 0)
        elif display_confidence > 0.85:
            primary_color = (0, 255, 0)
            bg_color = (0, 60, 0)
        elif display_confidence > 0.75:
            primary_color = (0, 255, 255)
            bg_color = (0, 60, 60)
        elif display_confidence > 0.65:
            primary_color = (0, 165, 255)
            bg_color = (0, 40, 80)
        else:
            primary_color = (0, 0, 255)
            bg_color = (0, 0, 80)
        
        # Main status message
        status_y = 40
        if result.detection_status == DetectionStatus.AUTO_SAVED:
            status_msg = "🎉 MEASUREMENT SUCCESSFULLY SAVED!"
            cv2.putText(frame, status_msg, (20, status_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, primary_color, 2)
        else:
            cv2.putText(frame, result.position_message, (20, status_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, primary_color, 2)
        
        # Calibration status
        calib_y = status_y + 30
        if self.camera_calibration.is_calibrated:
            calib_msg = f"📐 Calibrated (error: {result.calibration_quality:.2f}px)"
            calib_color = (0, 255, 0) if result.calibration_quality < 1.0 else (0, 255, 255)
        else:
            calib_msg = "⚠️ Uncalibrated - Reduced accuracy"
            calib_color = (0, 0, 255)
        
        cv2.putText(frame, calib_msg, (20, calib_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, calib_color, 1)
        
        # Stability progress bar
        if result.stability_frames > 0:
            stability_text = f"Stability: {result.stability_frames}/{self.max_stability_frames} frames"
            stability_progress = min(1.0, result.stability_frames / self.max_stability_frames)
            
            bar_x = 20
            bar_y = calib_y + 35
            bar_width = 300
            bar_height = 15
            
            # Background bar
            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (50, 50, 50), -1)
            
            # Progress fill
            fill_width = int(bar_width * stability_progress)
            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + fill_width, bar_y + bar_height), primary_color, -1)
            
            # Progress text
            cv2.putText(frame, stability_text, (bar_x, bar_y - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # Main measurements panel
        panel_x = 20
        panel_y = calib_y + 70
        panel_width = 420
        panel_height = 180
        
        # Semi-transparent background
        cv2.rectangle(overlay, (panel_x, panel_y), (panel_x + panel_width, panel_y + panel_height), bg_color, -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # Measurements text
        text_y = panel_y + 25
        line_spacing = 30
        
        # Height
        height_text = f"Height: {display_height:.1f} ± {result.uncertainty_height:.1f} cm"
        cv2.putText(frame, height_text, (panel_x + 15, text_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # Weight
        text_y += line_spacing
        weight_text = f"Weight: {display_weight:.1f} ± {result.uncertainty_weight:.1f} kg"
        cv2.putText(frame, weight_text, (panel_x + 15, text_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # BMI
        if display_height > 0:
            height_m = display_height / 100
            bmi = display_weight / (height_m ** 2)
            
            if bmi < 18.5:
                bmi_category = "Underweight"
                bmi_color = (0, 165, 255)
            elif bmi < 25:
                bmi_category = "Normal"
                bmi_color = (0, 255, 0)
            elif bmi < 30:
                bmi_category = "Overweight"
                bmi_color = (0, 255, 255)
            else:
                bmi_category = "Obese"
                bmi_color = (0, 0, 255)
            
            text_y += line_spacing
            bmi_text = f"BMI: {bmi:.1f} ({bmi_category})"
            cv2.putText(frame, bmi_text, (panel_x + 15, text_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, bmi_color, 2)
        
        # Confidence
        text_y += line_spacing
        confidence_text = f"Accuracy: {display_confidence:.1%}"
        cv2.putText(frame, confidence_text, (panel_x + 15, text_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # Processing time
        text_y += line_spacing
        time_text = f"Processing: {result.processing_time_ms:.1f}ms"
        cv2.putText(frame, time_text, (panel_x + 15, text_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        # Instructions panel
        instr_x = width - 350
        instr_y = 40
        instr_width = 330
        instr_height = 120
        
        cv2.rectangle(overlay, (instr_x, instr_y), (instr_x + instr_width, instr_y + instr_height), (40, 40, 40), -1)
        cv2.addWeighted(overlay, 0.8, frame, 0.2, 0, frame)
        
        instructions = [
            "Controls:",
            "'q' - Quit",
            "'s' - Save measurement",
            "'r' - Reset stability",
            "'c' - Toggle auto-save",
            "'k' - Recalibrate camera"
        ]
        
        for i, instruction in enumerate(instructions):
            cv2.putText(frame, instruction, (instr_x + 10, instr_y + 20 + i * 18), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    def _draw_no_human_detected(self, frame: np.ndarray, result: MeasurementResult):
        """Draw no human detected message"""
        height, width = frame.shape[:2]
        
        # Large warning message
        cv2.putText(frame, "NO HUMAN DETECTED", (width//2 - 200, height//2 - 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
        
        cv2.putText(frame, "Please stand in front of the camera", (width//2 - 250, height//2), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
        
        cv2.putText(frame, "Ensure good lighting and full body visibility", (width//2 - 300, height//2 + 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 100, 255), 2)
    
    def _draw_partial_body_detected(self, frame: np.ndarray, result: MeasurementResult):
        """Draw partial body detected message"""
        height, width = frame.shape[:2]
        
        # Warning message
        cv2.putText(frame, "ADJUST YOUR POSITION", (width//2 - 200, height//2 - 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 165, 255), 3)
        
        cv2.putText(frame, result.position_message, (50, height//2), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 165, 255), 2)
        
        cv2.putText(frame, "Stand 2-3 meters from camera", (width//2 - 200, height//2 + 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 200, 255), 2)


def main():
    """Main function to run the enhanced height and weight estimation system"""
    print("🚀 Enhanced Height & Weight Estimation System v3.0")
    print("📊 Maximum Achievable Accuracy with Single Camera")
    print("🎯 Research-Grade Implementation with Uncertainty Quantification")
    print("=" * 70)
    
    try:
        # Initialize the enhanced system
        estimator = EnhancedHeightWeightEstimator(
            use_gpu=True,
            calibration_file="camera_calibration.yaml"
        )
        
        print("✅ System initialized successfully")
        
        # Check if user wants to calibrate first
        if not estimator.camera_calibration.is_calibrated:
            print("\n🎯 Camera calibration is recommended for best accuracy")
            response = input("Do you want to calibrate the camera now? (y/n): ").lower().strip()
            if response == 'y':
                estimator.calibrate_camera()
        
        print("🎥 Starting camera...")
        
        # Start real-time processing
        estimator.start_enhanced_real_time_processing(video_source=0)
        
    except KeyboardInterrupt:
        print("\n⛔ Application interrupted by user")
    except Exception as e:
        print(f"❌ Error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("🔚 Application closed")


if __name__ == "__main__":
    main()

